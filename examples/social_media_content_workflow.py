import os
import asyncio
import textwrap
import datetime
from dotenv import load_dotenv
from evoagentx.models.openai_model import OpenAILLM
from evoagentx.models.model_configs import LLMConfig
from evoagentx.workflow import WorkFlow, WorkFlowGraph
from evoagentx.workflow.workflow_graph import WorkFlowNode, WorkFlowEdge
from evoagentx.agents import CustomizeAgent, AgentManager
from evoagentx.prompts import StringTemplate, ChatTemplate
from evoagentx.models import OpenAILLMConfig
from evoagentx.tools.search_ddgs import DDGSSearchToolkit
from evoagentx.tools.image_analysis import ImageAnalysisTool
from evoagentx.tools.flux_image_generation import FluxImageGenerationTool

load_dotenv()

# éœ€è¦çš„APIå¯†é’¥
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
BFL_API_KEY = os.getenv("BFL_API_KEY")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

# é…ç½®LLM
llm_config = OpenAILLMConfig(
    model="gpt-4o-mini", 
    openai_key=OPENAI_API_KEY, 
    stream=True, 
    output_response=True
)

def create_prompt_analysis_agent():
    """
    Agent 0: Prompt Analysis Agent
    è´Ÿè´£è§£æç”¨æˆ·è¾“å…¥çš„promptï¼Œç¡®å®šç ”ç©¶ä¸»é¢˜ã€æ˜¯å¦éœ€è¦å›¾ç‰‡ç”Ÿæˆä»¥åŠå›¾ç‰‡æ•°é‡å’Œå†…å®¹
    """
    
    prompt_analysis_agent = CustomizeAgent(
        name="PromptAnalysisAgent",
        description="Analyzes user prompts to determine research topics and image generation requirements",
        prompt_template=ChatTemplate(
            instruction="You are a prompt analysis specialist who breaks down user requests into structured research and content generation tasks.",
            context="You analyze user prompts to determine: 1) The main research topic, 2) How many images are required, 3) What each image should contain. You should also preserve the original user prompt for downstream processing.",
            constraints=[
                "Always provide a clear research topic summary",
                "Specify exact number of images needed",
                "Describe what each image should contain"
            ],
            demonstrations=[]
        ),
        llm_config=llm_config,
        inputs=[
            {"name": "user_prompt", "type": "string", "description": "User's original input prompt"}
        ],
        outputs=[
            {"name": "research_topic", "type": "string", "description": "Summarized research topic"},
            {"name": "image_count", "type": "integer", "description": "Number of images to generate"},
            {"name": "image_descriptions", "type": "string", "description": "Descriptions for each image"},
            {"name": "user_prompt", "type": "string", "description": "Original user prompt"}
        ]
    )
    
    return prompt_analysis_agent

def create_research_agent():
    """
    Agent 1: Research Agent with Image Analysis
    è´Ÿè´£ä½¿ç”¨ DDGS æœç´¢è·å–çƒ­ç‚¹ä¿¡æ¯å’Œç›¸å…³èµ„æ–™ï¼Œå¹¶åˆ†æå›¾ç‰‡å†…å®¹
    """
    
    # åˆ›å»º DDGS æœç´¢å·¥å…·åŒ…
    all_tools = []
    
    ddgs_toolkit = DDGSSearchToolkit(
        name="DDGSSearchToolkit",
        num_search_pages=5,
        max_content_words=500,
        backend="auto",
        region="us-en"
    )
    search_tools = ddgs_toolkit.get_tools()
    all_tools.extend(search_tools)
    
    # æ·»åŠ å›¾ç‰‡åˆ†æå·¥å…·ï¼ˆå¦‚æœæœ‰APIå¯†é’¥ï¼‰
    if OPENROUTER_API_KEY:
        image_analysis_tool = ImageAnalysisTool(
            api_key=OPENROUTER_API_KEY, 
            model="openai/gpt-4o-mini"
        )
        all_tools.append(image_analysis_tool)
    
    research_agent = CustomizeAgent(
        name="SearchResearchAgent",
        description="Web research agent using DDGS search and image analysis capabilities",
        prompt_template=ChatTemplate(
            instruction="You are a professional web research assistant specializing in social media content research. Your goal is to gather comprehensive information about trending topics",
            context="You have access to search the web for current information. You can also analyze images to understand visual content trends. CRITICAL: You MUST use the ddgs_search tool first to gather comprehensive information before proceeding with any analysis. Never provide information without searching first. Always search for current trends, statistics, and recent developments related to the research topic.",
            constraints=[
                "CRITICAL: You MUST use the ddgs_search tool to search for current information",
                "Search for content specifically relevant to the target platform",
                "Always search for recent trends, statistics, and developments",
                "Never provide information without first searching the web"
            ],
            demonstrations=[]
        ),
        llm_config=llm_config,
        inputs=[
            {"name": "research_topic", "type": "string", "description": "The topic to research"},
            {"name": "platform", "type": "string", "description": "Target social media platform"}
        ],
        outputs=[
            {"name": "research_info", "type": "string", "description": "Comprehensive research report with text and visual insights"}
        ],
        tools=all_tools
    )
    
    return research_agent

def create_content_generation_agent():
    """
    Agent 2: Content Generation Agent
    åŸºäºç ”ç©¶ä¿¡æ¯ç”Ÿæˆç¤¾äº¤åª’ä½“æ¨æ–‡å†…å®¹
    """
    
    content_agent = CustomizeAgent(
        name="ContentGenerationAgent", 
        description="Social media content creation specialist",
        prompt_template=ChatTemplate(
            instruction="You are an expert social media content creator who transforms research insights into engaging, viral-worthy posts.",
            context="You specialize in creating platform-specific content that drives engagement. You understand current social media trends, algorithm preferences, and audience psychology.",
            constraints=[
                "Content must be original and authentic",
                "Match the specified style and platform requirements",
                "Include engaging hooks and clear calls-to-action"
            ],
            demonstrations=[]
        ),
        llm_config=llm_config,
        inputs=[
            {"name": "research_info", "type": "string", "description": "Research information from previous step"},
            {"name": "user_prompt", "type": "string", "description": "User input prompt for content generation"}
        ],
        outputs=[
            {"name": "post_content", "type": "string", "description": "Generated social media post content"}
        ]
    )
    
    return content_agent

def create_image_generation_agent(save_path: str = "./social_media_output"):
    """
    Agent 3: Image Generation Agent
    åŸºäºå†…å®¹ç”Ÿæˆé…å¥—çš„ç¤¾äº¤åª’ä½“å›¾ç‰‡
    
    Args:
        save_path: ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸º"./social_media_output"
    """
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(save_path, exist_ok=True)
    
    # åˆ›å»ºå›¾ç‰‡ç”Ÿæˆå·¥å…·
    image_gen_tool = FluxImageGenerationTool(
        api_key=BFL_API_KEY, 
        save_path=save_path
    )
    
    image_agent = CustomizeAgent(
        name="ImageGenerationAgent",
        description="Social media image creation specialist",
        prompt_template=ChatTemplate(
            instruction="You are a professional visual content creator specializing in social media imagery. Your role is to generate images using the flux_image_generation tool based on the provided descriptions and research information.",
            context="You understand visual trends across different social media platforms and know how to create images that stop the scroll and drive engagement. Your images should be optimized for mobile viewing and social media algorithms. CRITICAL: You MUST use the flux_image_generation tool to create actual images.",
            constraints=[
                "CRITICAL: You MUST use the flux_image_generation tool to create actual images",
                "Generate images based on the provided image descriptions and research information",
                "Create high-quality, engaging visuals optimized for social media",
                "Always call the flux_image_generation tool with appropriate prompts"
            ],
            demonstrations=[]
        ),
        llm_config=llm_config,
        inputs=[
            {"name": "research_info", "type": "string", "description": "Research information from search results"},
            {"name": "image_descriptions", "type": "string", "description": "Image descriptions from prompt analysis"},
        ],
        outputs=[
            {"name": "image_path", "type": "string", "description": "Path to generated image file"}
        ],
        tools=[image_gen_tool]
    )
    
    return image_agent

def create_social_media_workflow(save_path: str = "./social_media_output", load_from_file: str = None):
    """
    åˆ›å»ºå®Œæ•´çš„ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆå·¥ä½œæµ
    åŒ…å«å››ä¸ªAgentï¼šPrompt Analysis -> Research -> Content Generation -> Image Generation
    
    Args:
        save_path: ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸º"./social_media_output"
    """
    
    # 1. åˆ›å»ºå››ä¸ªAgent
    prompt_analysis_agent = create_prompt_analysis_agent()
    research_agent = create_research_agent()
    content_agent = create_content_generation_agent()
    image_agent = create_image_generation_agent(save_path)
    
    # 2. åˆ›å»ºå·¥ä½œæµèŠ‚ç‚¹
    nodes = [
        WorkFlowNode(
            name="prompt_analysis",
            description="Analyze user prompt to determine research topic and image requirements",
            agents=[prompt_analysis_agent],
            inputs=[
                {"name": "user_prompt", "type": "string", "description": "User's original input", "required": True}
            ],
            outputs=[
                {"name": "research_topic", "type": "string", "description": "Research topic", "required": True},
                {"name": "image_count", "type": "integer", "description": "Number of images", "required": True},
                {"name": "image_descriptions", "type": "string", "description": "Image descriptions", "required": True},
                {"name": "user_prompt", "type": "string", "description": "Original user prompt", "required": True}
            ]
        ),
        WorkFlowNode(
            name="research",
            description="Research trending topics using DDGS search",
            agents=[research_agent],
            inputs=[
                {"name": "research_topic", "type": "string", "description": "Topic to research", "required": True},
                {"name": "platform", "type": "string", "description": "Target platform", "required": True}
            ],
            outputs=[
                {"name": "research_info", "type": "string", "description": "Research findings", "required": True}
            ]
        ),
        WorkFlowNode(
            name="content_generation",
            description="Generate social media content based on research",
            agents=[content_agent],
            inputs=[
                {"name": "research_info", "type": "string", "description": "Research information", "required": True},
                {"name": "user_prompt", "type": "string", "description": "User input prompt", "required": True}
            ],
            outputs=[
                {"name": "post_content", "type": "string", "description": "Generated content", "required": True}
            ]
        ),
        WorkFlowNode(
            name="image_generation",
            description="Generate images for social media content",
            agents=[image_agent],
            inputs=[
                {"name": "research_info", "type": "string", "description": "Research context", "required": True},
                {"name": "image_descriptions", "type": "string", "description": "Image descriptions", "required": True}
            ],
            outputs=[
                {"name": "image_path", "type": "string", "description": "Path to generated image", "required": True}
            ]
        )
    ]
    
    # 3. å®šä¹‰å·¥ä½œæµè¾¹ï¼ˆæ•°æ®æµå‘ï¼‰
    edges = [
        # Prompt Analysis -> Research
        WorkFlowEdge(source="prompt_analysis", target="research"),
        # Prompt Analysis -> Content Generation (ä¼ é€’user_prompt)
        WorkFlowEdge(source="prompt_analysis", target="content_generation"),
        # Prompt Analysis -> Image Generation (ä¼ é€’image_descriptions)
        WorkFlowEdge(source="prompt_analysis", target="image_generation"),
        # Research -> Content Generation
        WorkFlowEdge(source="research", target="content_generation"),
        # Research -> Image Generation (ä¸ºå›¾ç‰‡ç”Ÿæˆæä¾›é¢å¤–ä¸Šä¸‹æ–‡)
        WorkFlowEdge(source="research", target="image_generation")
    ]
    
    # 4. åˆ›å»ºå·¥ä½œæµå›¾
    if load_from_file and os.path.exists(load_from_file):
        print(f"ğŸ“‚ ä»æ–‡ä»¶åŠ è½½workflow: {load_from_file}")
        graph = WorkFlowGraph.from_file(load_from_file)
    else:
        graph = WorkFlowGraph(
            goal="Create social media content with prompt analysis, research, content generation, and image creation",
            nodes=nodes,
            edges=edges
        )
    
    # 5. åˆ›å»ºAgent Manager
    agents = [prompt_analysis_agent, research_agent, content_agent, image_agent]
    agent_manager = AgentManager(agents=agents)
    
    # 6. åˆ›å»ºå®Œæ•´å·¥ä½œæµ
    workflow = WorkFlow(
        graph=graph,
        llm= OpenAILLM(llm_config),
        agent_manager=agent_manager
    )
    
    # ä¿å­˜workflowé…ç½®åˆ°JSONæ–‡ä»¶
    os.makedirs("examples/output", exist_ok=True)
    save_path = "examples/output/social_media_workflow.json"
    graph.save_module(save_path)
    print(f"âœ… Workflowå·²ä¿å­˜åˆ°: {save_path}")
    
    return workflow

async def test_complete_workflow(save_path: str = "./social_media_output", load_workflow: bool = False):
    """
    æµ‹è¯•å®Œæ•´çš„å››èŠ‚ç‚¹å·¥ä½œæµ
    
    Args:
        save_path: ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸º"./social_media_output"
    """
    # æ£€æŸ¥APIå¯†é’¥
    required_keys = {
        "OPENAI_API_KEY": OPENAI_API_KEY,
        "BFL_API_KEY": BFL_API_KEY,
    }
    
    # OPENROUTER_API_KEYæ˜¯å¯é€‰çš„ï¼Œç”¨äºå›¾ç‰‡åˆ†æ
    optional_keys = {
        "OPENROUTER_API_KEY": OPENROUTER_API_KEY
    }
    
    missing_keys = [key for key, value in required_keys.items() if not value]
    if missing_keys:
        print("âŒ ç¼ºå°‘å¿…éœ€çš„APIå¯†é’¥:")
        for key in missing_keys:
            print(f"   - {key}")
        print("\nè¯·åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ æ‰€æœ‰å¿…éœ€çš„APIå¯†é’¥")
        return
    
    # æ£€æŸ¥å¯é€‰APIå¯†é’¥
    missing_optional = [key for key, value in optional_keys.items() if not value]
    if missing_optional:
        print("âš ï¸  å¯é€‰APIå¯†é’¥æœªé…ç½®ï¼ˆå›¾ç‰‡åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨ï¼‰:")
        for key in missing_optional:
            print(f"   - {key}")
        print()
    
    print("ğŸš€ æµ‹è¯•å®Œæ•´çš„ç¤¾äº¤åª’ä½“å†…å®¹å·¥ä½œæµ")
    print("=" * 60)
    
    # åˆ›å»ºå·¥ä½œæµ
    if load_workflow:
        workflow_file = "examples/output/social_media_workflow.json"
        if os.path.exists(workflow_file):
            print(f"ğŸ”„ ä»ä¿å­˜çš„æ–‡ä»¶åŠ è½½workflow: {workflow_file}")
            workflow = create_social_media_workflow(save_path, load_from_file=workflow_file)
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°ä¿å­˜çš„workflowæ–‡ä»¶: {workflow_file}")
            print("ğŸ“ åˆ›å»ºæ–°çš„workflow...")
            workflow = create_social_media_workflow(save_path)
    else:
        workflow = create_social_media_workflow(save_path)
        print("âœ… å®Œæ•´å·¥ä½œæµåˆ›å»ºæˆåŠŸ!")
        print(f"ğŸ“ ä¿å­˜è·¯å¾„: {save_path}")
        
        # æµ‹è¯•æ¡ˆä¾‹
        test_cases = [
            {
                "user_prompt": "Create a professional post about AI productivity tools for LinkedIn with 2 images. Search for current trends and statistics about AI adoption in the workplace, productivity improvements, and popular AI tools used by professionals. Generate images showing professionals using AI tools, productivity dashboards, and modern workplace technology.",
                "platform": "LinkedIn"
            },
            {
                "user_prompt": "Create a casual post about healthy morning routines for Instagram with 1 image. Search for current wellness trends, morning routine statistics, and popular health practices. Generate an image showing a peaceful morning routine with healthy breakfast, meditation, and wellness activities.",
                "platform": "Instagram"
            },
            {
                "user_prompt": "Create a humorous post about remote work tips for Twitter with 2 images. Search for funny remote work anecdotes, common work-from-home challenges, and viral remote work memes. Generate images showing humorous remote work situations, pets interrupting meetings, and creative home office setups.",
                "platform": "Twitter"
            },
            {
                "user_prompt": "Create an informative post about sustainable living practices for Facebook with 3 images. Search for current trends and statistics about eco-friendly lifestyle choices, renewable energy adoption, and zero-waste living. Generate images showing sustainable home practices, green energy solutions, and eco-friendly daily routines.",
                "platform": "Facebook"
            }
        ]
        
        print("\nğŸ¯ å¯é€‰æµ‹è¯•æ¡ˆä¾‹ï¼š")
        print("=" * 60)
        for i, case in enumerate(test_cases, 1):
            print(f"\n{i}. å¹³å°: {case['platform']}")
            print(f"   ä¸»é¢˜: {case['user_prompt'][:100]}...")
            print(f"   å®Œæ•´æè¿°:")
            
            # å°†é•¿æ–‡æœ¬æŒ‰è¡Œåˆ†å‰²å¹¶æ·»åŠ ç¼©è¿›
            wrapped_text = textwrap.fill(case['user_prompt'], width=70, initial_indent="      ", subsequent_indent="      ")
            print(wrapped_text)
            print("-" * 60)
        
        print("\nè¯·é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹ï¼ˆè¾“å…¥æ•°å­—1-4ï¼‰:")
        try:
            choice = int(input().strip())
            if 1 <= choice <= len(test_cases):
                selected_case = test_cases[choice - 1]
                print(f"\nğŸ¯ æ‰§è¡Œæ¡ˆä¾‹: {selected_case['user_prompt']}")
                print(f"   å¹³å°: {selected_case['platform']}")
                
                # æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
                result = await workflow.async_execute(
                    inputs=selected_case,
                    task_name="social media content creation",
                    goal="Create social media content with prompt analysis, research, content generation, and image creation"
                )
                
                print("\n" + "="*60)
                print("ğŸ‰ å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
                print("="*60)
                
                print("\nğŸ“‹ å®Œæ•´ç»“æœ:")
                print("-" * 40)
                print(result)
                
                # ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶
                try:
                    # åˆ›å»ºä¿å­˜ç›®å½•
                    os.makedirs(save_path, exist_ok=True)
                    
                    # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŸºäºæ—¶é—´æˆ³ï¼‰
                    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                    content_filename = f"social_media_content_{timestamp}.txt"
                    content_filepath = os.path.join(save_path, content_filename)
                    
                    # ä¿å­˜å†…å®¹
                    with open(content_filepath, "w", encoding="utf-8") as f:
                        f.write("=== ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆç»“æœ ===\n")
                        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                        f.write(f"æµ‹è¯•æ¡ˆä¾‹: {selected_case['user_prompt']}\n")
                        f.write(f"ç›®æ ‡å¹³å°: {selected_case['platform']}\n")
                        f.write("\n" + "="*50 + "\n")
                        f.write(result)
                    
                    print(f"\nğŸ’¾ å†…å®¹å·²ä¿å­˜åˆ°: {content_filepath}")
                    
                except Exception as e:
                    print(f"âš ï¸ ä¿å­˜å†…å®¹æ—¶å‡ºé”™: {e}")
                
                return result
                
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
                
        except (ValueError, KeyboardInterrupt):
            print("\nğŸ’¡ ä½ ä¹Ÿå¯ä»¥ç›´æ¥è¿è¡Œ:")
            print('result = workflow.run(user_prompt="your prompt", platform="LinkedIn")')
                    
        except Exception as e:
            print(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            print("\nğŸ’¡ å¯èƒ½çš„é—®é¢˜:")
            print("1. ä¾èµ–å®‰è£…: pip install browser-use")
            print("2. æµè§ˆå™¨: éœ€è¦Chrome/Chromium")
            print("3. ç½‘ç»œè¿æ¥é—®é¢˜")
            print("4. APIå¯†é’¥é…ç½®é”™è¯¯")

def test_direct_agent():
    """
    ç›´æ¥æµ‹è¯•å•ä¸ªAgentï¼ˆä¸é€šè¿‡workflowï¼‰
    """
    
    try:
        agent = create_content_generation_agent()
        
        # æ¨¡æ‹Ÿæ›´çœŸå®çš„research_infoå’Œpromptè¾“å…¥
        research_info = """
        AI Productivity Tools Market Analysis 2024:
        
        Key Findings:
        - 73% of professionals now use AI tools daily for productivity
        - Average time savings: 40% faster task completion
        - Top AI tools: ChatGPT (45%), Notion AI (32%), Grammarly (28%)
        - 67% report reduced burnout levels with AI assistance
        - 89% say AI enhances creativity and problem-solving
        
        Trending Topics:
        - AI-powered project management tools
        - Automated content creation platforms
        - Smart calendar and scheduling assistants
        - AI-driven data analysis tools
        
        Platform-Specific Insights:
        - LinkedIn: Professional development and career growth focus
        - High engagement with thought leadership content
        - Preference for data-driven insights and actionable tips
        """
        
        prompt = "Create a professional LinkedIn post about AI productivity tools that drives engagement and positions the author as a thought leader"
        
        result = agent(inputs={
            "research_info": research_info,
            "prompt": prompt
        })
        
        print("\nğŸ“‹ Content Generation Agent æµ‹è¯•ç»“æœ:")
        print("=" * 50)
        print("è¾“å…¥ research_info:")
        print("-" * 30)
        print(research_info[:200] + "...")
        print("\nè¾“å…¥ prompt:")
        print("-" * 30)
        print(prompt)
        print("\nè¾“å‡º post_content:")
        print("-" * 30)
        print(result.content.post_content)
        
    except Exception as e:
        print(f"âŒ ç›´æ¥æµ‹è¯•å¤±è´¥: {e}")

def test_prompt_analysis_agent():
    """
    æµ‹è¯•Prompt Analysis Agent
    """
    
    try:
        agent = create_prompt_analysis_agent()
        
        test_prompts = [
            "Create a professional post about AI productivity tools for LinkedIn",
            "Create a casual post about healthy morning routines for Instagram with 2 images",
            "Create a humorous post about remote work tips for Twitter"
        ]
        
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\nğŸ§ª æµ‹è¯•æ¡ˆä¾‹ {i}: {prompt}")
            print("-" * 50)
            
            result = agent(inputs={"user_prompt": prompt})
            
            print(f"Research Topic: {result.content.research_topic}")
            print(f"Image Count: {result.content.image_count}")
            print(f"Image Descriptions: {result.content.image_descriptions}")
            print()
            
    except Exception as e:
        print(f"âŒ Prompt Analysis Agent æµ‹è¯•å¤±è´¥: {e}")

def test_tools():
    """
    æµ‹è¯•å·¥å…·æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    print("ğŸ§ª æµ‹è¯•å·¥å…·åŠŸèƒ½")
    print("=" * 50)
    
    # æµ‹è¯•DDGSæœç´¢å·¥å…·
    print("1. æµ‹è¯•DDGSæœç´¢å·¥å…·...")
    try:
        ddgs_toolkit = DDGSSearchToolkit(
            name="DDGSSearchToolkit",
            num_search_pages=2,
            max_content_words=200,
            backend="auto",
            region="us-en"
        )
        search_tools = ddgs_toolkit.get_tools()
        if search_tools:
            search_tool = search_tools[0]
            result = search_tool(query="AI productivity tools", num_search_pages=1)
            print(f"âœ… DDGSæœç´¢å·¥å…·æµ‹è¯•æˆåŠŸ")
            print(f"æœç´¢ç»“æœæ•°é‡: {len(result.get('results', []))}")
            if result.get('error'):
                print(f"âš ï¸ æœç´¢é”™è¯¯: {result['error']}")
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°DDGSæœç´¢å·¥å…·")
    except Exception as e:
        print(f"âŒ DDGSæœç´¢å·¥å…·æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•å›¾ç‰‡ç”Ÿæˆå·¥å…·
    print("\n2. æµ‹è¯•å›¾ç‰‡ç”Ÿæˆå·¥å…·...")
    try:
        if not BFL_API_KEY:
            print("âŒ BFL_API_KEYæœªé…ç½®ï¼Œè·³è¿‡å›¾ç‰‡ç”Ÿæˆæµ‹è¯•")
        else:
            image_gen_tool = FluxImageGenerationTool(
                api_key=BFL_API_KEY, 
                save_path="./test_output"
            )
            result = image_gen_tool(prompt="A simple test image", aspect_ratio="1:1")
            print(f"âœ… å›¾ç‰‡ç”Ÿæˆå·¥å…·æµ‹è¯•æˆåŠŸ")
            print(f"ç”Ÿæˆå›¾ç‰‡è·¯å¾„: {result.get('file_path', 'N/A')}")
    except Exception as e:
        print(f"âŒ å›¾ç‰‡ç”Ÿæˆå·¥å…·æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    """
    ğŸ”§ é…ç½®è¯´æ˜ï¼š
    
    å®Œæ•´çš„å››èŠ‚ç‚¹ç¤¾äº¤åª’ä½“å†…å®¹å·¥ä½œæµ
    
    1. å¿…éœ€ç¯å¢ƒå˜é‡ï¼š
       - OPENAI_API_KEY: OpenAI APIå¯†é’¥ (ç”¨äºLLM)
       - BFL_API_KEY: Black Forest Labs APIå¯†é’¥ (ç”¨äºå›¾ç‰‡ç”Ÿæˆ)
    
    2. å¯é€‰ç¯å¢ƒå˜é‡ï¼š
       - OPENROUTER_API_KEY: OpenRouter APIå¯†é’¥ (ç”¨äºå›¾ç‰‡åˆ†æï¼Œå¯é€‰)
    
    3. ä¾èµ–å®‰è£…ï¼š
       - pip install selenium (æµè§ˆå™¨è‡ªåŠ¨åŒ–)
       - pip install Pillow (ç”¨äºå›¾ç‰‡æ˜¾ç¤º)
       - pip install ddgs (ç”¨äºæœç´¢åŠŸèƒ½)
       - éœ€è¦å®‰è£…Chromeæµè§ˆå™¨
    
    4. å·¥ä½œæµèŠ‚ç‚¹ï¼š
       - Node 0: Prompt Analysis Agent (è§£æç”¨æˆ·è¾“å…¥)
       - Node 1: Research Agent (DDGSæœç´¢ + å¯é€‰å›¾ç‰‡åˆ†æ)
       - Node 2: Content Generation Agent (åˆ›å»ºæ¨æ–‡å†…å®¹)
       - Node 3: Image Generation Agent (ç”Ÿæˆé…å›¾)
    
    5. æ•°æ®æµå‘ï¼š
       Prompt Analysis -> Research -> Content Generation
       Research -> Image Generation (æä¾›é¢å¤–ä¸Šä¸‹æ–‡)
    """
    
    print("ğŸ“± å®Œæ•´ç¤¾äº¤åª’ä½“å†…å®¹å·¥ä½œæµ")
    print("å››èŠ‚ç‚¹å·¥ä½œæµï¼šPrompt Analysis -> Research -> Content -> Image")
    print("=" * 60)
    
    # æµ‹è¯•å·¥å…·åŠŸèƒ½
    # test_tools()
    
    # è¿è¡Œå®Œæ•´å·¥ä½œæµæµ‹è¯•
    # å¯ä»¥é€šè¿‡ä¿®æ”¹è¿™ä¸ªè·¯å¾„æ¥è‡ªå®šä¹‰ä¿å­˜ä½ç½®
    save_path = "./social_media_output"
    
    # é€‰æ‹©è¿è¡Œæ¨¡å¼
    print("\nğŸ¯ é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. åˆ›å»ºæ–°çš„workflow (é»˜è®¤)")
    print("2. ä»ä¿å­˜çš„æ–‡ä»¶åŠ è½½workflow")
    print("3. æµ‹è¯•å·¥å…·åŠŸèƒ½")
    print("4. æµ‹è¯•Prompt Analysis Agent")
    print("5. æµ‹è¯•Content Generation Agent")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-5ï¼Œé»˜è®¤ä¸º1): ").strip()
        if not choice:
            choice = "1"
        
        if choice == "1":
            print("\nğŸš€ åˆ›å»ºæ–°çš„workflow...")
            asyncio.run(test_complete_workflow(save_path, load_workflow=False))
        elif choice == "2":
            print("\nğŸ”„ ä»ä¿å­˜çš„æ–‡ä»¶åŠ è½½workflow...")
            asyncio.run(test_complete_workflow(save_path, load_workflow=True))
        elif choice == "3":
            print("\nğŸ§ª æµ‹è¯•å·¥å…·åŠŸèƒ½...")
            test_tools()
        elif choice == "4":
            print("\nğŸ§ª æµ‹è¯•Prompt Analysis Agent...")
            test_prompt_analysis_agent()
        elif choice == "5":
            print("\nğŸ§ª æµ‹è¯•Content Generation Agent...")
            test_direct_agent()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼")
            asyncio.run(test_complete_workflow(save_path, load_workflow=False))
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
    
    # æµ‹è¯•Prompt Analysis Agent
    # test_prompt_analysis_agent()
    
    # æµ‹è¯•Content Generation Agent
    # test_direct_agent() 
import os 
import json
from dotenv import load_dotenv
from typing import Any

from evoagentx.benchmark import MATH
from evoagentx.models import OpenAILLMConfig, OpenAILLM
from evoagentx.optimizers import MiproOptimizer
from evoagentx.utils.mipro_utils.register_utils import MiproRegistry

# å¯¼å…¥æ–°çš„ mass_optimizer
from .mass_optimizer import (
    run_full_optimization,
    create_mass_workflow,
    MassOptimiser,
    MassWorkflow,
    MassBlock
)

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

MAX_BOOTSTRAPPED_DEMOS = 1
MAX_LABELED_DEMOS = 0
AUTO = "light"
NUM_THREADS = 16
EVALUATION_ROUNDS = 1

class MathSplits(MATH):
    """å‚è€ƒåŸå§‹ mass.py çš„ MathSplits ç±»"""

    def _load_data(self):
        # load the original test data 
        super()._load_data()
        # split the data into dev and test
        import numpy as np 
        np.random.seed(42)
        permutation = np.random.permutation(len(self._test_data))
        full_test_data = self._test_data
        # randomly select 100 samples for training and 100 samples for test
        self._train_data = [full_test_data[idx] for idx in permutation[:100]]
        self._test_data = [full_test_data[idx] for idx in permutation[100:200]]

    # define the input keys. 
    # If defined, the corresponding input key and value will be passed to the __call__ method of the program, 
    # i.e., program.__call__(**{k: v for k, v in example.items() if k in self.get_input_keys()})
    # If not defined, the program will be executed with the entire input example, i.e., program.__call__(**example)
    def get_input_keys(self):
        return ["problem"]
    
    # the benchmark must have a `evaluate` method that receives the program's `prediction` (output from the program's __call__ method) 
    # and the `label` (obtained using the `self.get_label` method) and return a dictionary of metrics. 
    def evaluate(self, prediction: Any, label: Any) -> dict:
        return super().evaluate(prediction, label)


def get_save_path(program):
    """è·å–ä¿å­˜è·¯å¾„"""
    return f"examples/mass/{program}"


def test_simple_workflow():
    """æµ‹è¯•ç®€å•çš„å·¥ä½œæµæ‰§è¡Œ"""
    print("=== æµ‹è¯•ç®€å•å·¥ä½œæµæ‰§è¡Œ ===")
    
    # åˆå§‹åŒ– LLM
    openai_config = OpenAILLMConfig(
        model="gpt-4o", 
        openai_key=OPENAI_API_KEY, 
        stream=True, 
        output_response=False
    )
    executor_llm = OpenAILLM(config=openai_config)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
    benchmark = MathSplits()
    
    # åˆ›å»ºç®€å•çš„å·¥ä½œæµ
    workflow = create_mass_workflow(executor_llm)
    
    # æµ‹è¯•å•ä¸ªé—®é¢˜
    test_problem = "What is 2 + 2?"
    print(f"æµ‹è¯•é—®é¢˜: {test_problem}")
    
    try:
        result, context = workflow(test_problem)
        print(f"ç»“æœ: {result}")
        print(f"ä¸Šä¸‹æ–‡: {context}")
        print("âœ… ç®€å•å·¥ä½œæµæµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ ç®€å•å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True


def test_individual_blocks():
    """æµ‹è¯•å„ä¸ªç‹¬ç«‹çš„ blocks"""
    print("\n=== æµ‹è¯•å„ä¸ªç‹¬ç«‹çš„ blocks ===")
    
    # åˆå§‹åŒ– LLM
    openai_config = OpenAILLMConfig(
        model="gpt-4o", 
        openai_key=OPENAI_API_KEY, 
        stream=True, 
        output_response=False
    )
    executor_llm = OpenAILLM(config=openai_config)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
    benchmark = MathSplits()
    
    # æµ‹è¯• Predictor
    from .blocks import create_predictor_agent
    predictor = create_predictor_agent(executor_llm)
    
    test_problem = "Solve: 3x + 5 = 20"
    print(f"æµ‹è¯• Predictor: {test_problem}")
    
    try:
        result = predictor(test_problem)
        print(f"Predictor ç»“æœ: {result}")
        print("âœ… Predictor æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ Predictor æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯• Aggregate
    from .blocks import create_aggregate
    aggregate = create_aggregate(predictor, n=3)
    
    print(f"æµ‹è¯• Aggregate: {test_problem}")
    
    try:
        result = aggregate(test_problem)
        print(f"Aggregate ç»“æœ: {result}")
        print("âœ… Aggregate æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ Aggregate æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True


def test_optimization_workflow():
    """æµ‹è¯•ä¼˜åŒ–å·¥ä½œæµï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
    print("\n=== æµ‹è¯•ä¼˜åŒ–å·¥ä½œæµï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰===")
    
    # åˆå§‹åŒ– LLM
    openai_config = OpenAILLMConfig(
        model="gpt-4o", 
        openai_key=OPENAI_API_KEY, 
        stream=True, 
        output_response=False
    )
    executor_llm = OpenAILLM(config=openai_config)
    optimizer_llm = OpenAILLM(config=openai_config)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
    benchmark = MathSplits()
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = create_mass_workflow(executor_llm)
    
    # è®¾ç½®ä¸€äº› blocks ä¸ºæ¿€æ´»çŠ¶æ€
    workflow.blocks[0].n = 1  # summarizer
    workflow.blocks[1].n = 3  # aggregater
    workflow.blocks[2].n = 0  # reflector (ä¸æ¿€æ´»)
    workflow.blocks[3].n = 1  # debater
    workflow.blocks[4].n = 0  # executer (ä¸æ¿€æ´»)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    mass = MassOptimiser(
        workflow=workflow,
        optimizer_llm=optimizer_llm,
        max_bootstrapped_demos=1,  # å‡å°‘ä»¥åŠ å¿«æµ‹è¯•
        max_labeled_demos=0,
        auto="light",
        eval_rounds=1,
        num_threads=4,  # å‡å°‘çº¿ç¨‹æ•°
        save_path="examples/mass/test_optimization",
        max_steps=2  # å‡å°‘æ­¥æ•°ä»¥åŠ å¿«æµ‹è¯•
    )
    
    try:
        print("å¼€å§‹ä¼˜åŒ–...")
        best_program = mass.optimize(benchmark=benchmark)
        print("âœ… ä¼˜åŒ–å·¥ä½œæµæµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_full_optimization():
    """æµ‹è¯•å®Œæ•´ä¼˜åŒ–æµç¨‹ï¼ˆå‚è€ƒåŸå§‹ main å‡½æ•°ï¼‰"""
    print("\n=== æµ‹è¯•å®Œæ•´ä¼˜åŒ–æµç¨‹ ===")
    
    # åˆå§‹åŒ– LLM
    openai_config = OpenAILLMConfig(
        model="gpt-4o", 
        openai_key=OPENAI_API_KEY, 
        stream=True, 
        output_response=False
    )
    executor_llm = OpenAILLM(config=openai_config)
    optimizer_llm = OpenAILLM(config=openai_config)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
    benchmark = MathSplits()
    
    try:
        print("å¼€å§‹å®Œæ•´ä¼˜åŒ–æµç¨‹...")
        best_program = run_full_optimization(executor_llm, optimizer_llm, benchmark)
        print("âœ… å®Œæ•´ä¼˜åŒ–æµç¨‹æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ å®Œæ•´ä¼˜åŒ–æµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_workflow_serialization():
    """æµ‹è¯•å·¥ä½œæµåºåˆ—åŒ–"""
    print("\n=== æµ‹è¯•å·¥ä½œæµåºåˆ—åŒ– ===")
    
    # åˆå§‹åŒ– LLM
    openai_config = OpenAILLMConfig(
        model="gpt-4o", 
        openai_key=OPENAI_API_KEY, 
        stream=True, 
        output_response=False
    )
    executor_llm = OpenAILLM(config=openai_config)
    
    # åˆ›å»ºå·¥ä½œæµ
    workflow = create_mass_workflow(executor_llm)
    
    # è®¾ç½®ä¸€äº›çŠ¶æ€
    workflow.blocks[0].n = 1
    workflow.blocks[1].n = 3
    workflow.blocks[2].n = 0
    workflow.blocks[3].n = 1
    workflow.blocks[4].n = 0
    
    try:
        # ä¿å­˜çŠ¶æ€
        state = workflow.get_state()
        print("âœ… çŠ¶æ€ä¿å­˜æˆåŠŸ")
        
        # ä¿®æ”¹çŠ¶æ€
        workflow.blocks[0].n = 5
        workflow.blocks[1].n = 7
        
        # æ¢å¤çŠ¶æ€
        workflow.set_state(state)
        
        # éªŒè¯æ¢å¤
        assert workflow.blocks[0].n == 1
        assert workflow.blocks[1].n == 3
        print("âœ… çŠ¶æ€æ¢å¤æˆåŠŸ")
        
        # æµ‹è¯•æ–‡ä»¶ä¿å­˜å’ŒåŠ è½½
        save_path = "examples/mass/test_workflow_config.json"
        workflow.save(save_path)
        print("âœ… å·¥ä½œæµé…ç½®ä¿å­˜æˆåŠŸ")
        
        # åˆ›å»ºæ–°çš„å·¥ä½œæµå¹¶åŠ è½½é…ç½®
        new_workflow = create_mass_workflow(executor_llm)
        new_workflow.load(save_path)
        print("âœ… å·¥ä½œæµé…ç½®åŠ è½½æˆåŠŸ")
        
        return True
    except Exception as e:
        print(f"âŒ å·¥ä½œæµåºåˆ—åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯• MATH æ•°æ®é›†...")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not OPENAI_API_KEY:
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs("examples/mass", exist_ok=True)
    
    # è¿è¡Œå„ä¸ªæµ‹è¯•
    tests = [
        ("ç®€å•å·¥ä½œæµ", test_simple_workflow),
        ("ç‹¬ç«‹ blocks", test_individual_blocks),
        ("ä¼˜åŒ–å·¥ä½œæµ", test_optimization_workflow),
        ("å·¥ä½œæµåºåˆ—åŒ–", test_workflow_serialization),
        ("å®Œæ•´ä¼˜åŒ–æµç¨‹", test_full_optimization),
    ]
    
    results = {}
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"è¿è¡Œæµ‹è¯•: {test_name}")
        print(f"{'='*50}")
        
        try:
            result = test_func()
            results[test_name] = result
        except Exception as e:
            print(f"âŒ æµ‹è¯• {test_name} å‘ç”Ÿå¼‚å¸¸: {e}")
            results[test_name] = False
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print(f"\n{'='*50}")
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    print(f"{'='*50}")
    
    passed = 0
    total = len(tests)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main()
